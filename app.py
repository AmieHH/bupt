import streamlit as st
from zhipuai import ZhipuAI


class MyQAApp:
    def __init__(self):
        # ä½¿ç”¨å›ºå®šçš„API Key
        self.api_key = "5022cd3dacef67b05354432743d43bbd.5gKOTuIkuWQoLbl9"
        self.client = ZhipuAI(api_key=self.api_key)
        self.response = None
        self.messages = []

    def run(self):
        st.title("ğŸ’¬ é‚®é‚®åŠ©æ‰‹")
        st.caption("ğŸš€ ä¸€æ¬¾åŒ—é‚®å­¦ç”Ÿå‡ºå“çš„æ ¡å›­äººå·¥æ™ºèƒ½åŠ©æ‰‹")

        # æ˜¾ç¤ºåˆå§‹çš„åŠ©æ‰‹æ¶ˆæ¯
        if not self.messages:
            self.messages.append({"role": "assistant", "content": "How can I help you?"})
            st.write("åŠ©æ‰‹: How can I help you?")

        for msg in self.messages:
            st.write(f"{msg['role']}: {msg['content']}")

        if prompt := st.text_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š"):
            self.ask_question(prompt)

    def ask_question(self, prompt):
        # ä¿®æ­£ä¸ºæ­£ç¡®çš„é”® 'role' è€Œä¸æ˜¯ 'store_role'
        self.messages.append({"role": "user", "content": prompt})

        # å‘é€é—®é¢˜å¹¶è·å–å›ç­”
        self.response = self.client.chat.completions.create(
            model="glm-4v",
            messages=self.messages,
            stream=True,
            tools=[
                {
                    "type": "retrieval",
                    "retrieval": {
                        "knowledge_id": "1765660633795276800",
                        "prompt_template": "å¦‚æœç”¨æˆ·é—®æ–‡æ¡£ä¸­çš„ç›¸å…³é—®é¢˜å°±ç›´æ¥å›ç­”ã€‚ä¸æ˜¯æ–‡æ¡£é‡Œçš„ç›¸å…³å†…å®¹ä½ å°±å‘Šè¯‰ç”¨æˆ·æˆ‘ä¸å¤ªæ¸…æ¥šï¼Œæˆ–è€…è®©ç”¨æˆ·å†é—®çš„å…·ä½“ä¸€ç‚¹ã€‚ä¸è¦å¤è¿°é—®é¢˜ï¼Œç›´æ¥å¼€å§‹å›ç­”ã€‚"
                    }
                }
            ],
        )

        # ä»responseä¸­è¯»å–å›ç­”
        msg = ""
        for chunk in self.response:
            msg += chunk.choices[0].delta.content

        self.messages.append({"role": "assistant", "content": msg})
        st.write(f"åŠ©æ‰‹: {msg}")


if __name__ == '__main__':
    qa_app = MyQAApp()
    qa_app.run()
